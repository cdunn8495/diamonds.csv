{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvYYe2PKC8gBpcIN3YrVqR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3t0h_xoHrKl",
        "outputId": "165f8bd7-4db1-4a84-d623-fc0e92c5cd12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "467/844 [===============>..............] - ETA: 7:15 - loss: 0.1725 - accuracy: 0.9459"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "cnn = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn.compile(optimizer='adam',\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "cnn.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "loss, accuracy = cnn.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "predictions = cnn.predict(X_test)\n",
        "\n",
        "images = X_test.reshape((10000, 28, 28))\n",
        "incorrect_predictions = []\n",
        "for i, (p, e) in enumerate(zip(predictions, y_test)):\n",
        "    predicted, expected = np.argmax(p), np.argmax(e)\n",
        "    if predicted != expected:\n",
        "        incorrect_predictions.append((i, images[i], predicted, expected))\n",
        "\n",
        "print(\"Number of incorrect predictions:\", len(incorrect_predictions))\n",
        "figure, axes = plt.subplots(nrows=4, ncols=6, figsize=(16, 12))\n",
        "for axes, item in zip(axes.ravel(), incorrect_predictions[:24]):\n",
        "    index, image, predicted, expected = item\n",
        "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
        "    axes.set_xticks([])\n",
        "    axes.set_yticks([])\n",
        "    axes.set_title(f'index: {index}\\np: {predicted}; e: {expected}')\n",
        "plt.tight_layout()\n",
        "\n",
        "def display_probabilities(prediction):\n",
        "    for index, probability in enumerate(prediction):\n",
        "        print(f'{index}: {probability:.10%}')\n",
        "\n",
        "print(\"Probabilities for some incorrect predictions:\")\n",
        "for i in range(3):\n",
        "    display_probabilities(predictions[incorrect_predictions[i][0]])\n"
      ]
    }
  ]
}